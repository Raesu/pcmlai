# Intro

## Research Question
Can we build predictive text models (word completion, sentence completion) but training a model on 4 million lines of tweets, blogs, and news articles?

## Data Sources
Kaggle Swiftkey data setLinks to an external site.

## Techniques to use
I will run extensive text analysis as exploratory analysis, then use cross validation across most of the classification methods (decision tree, multiclass logistic regression, SVM, random forest, KNN, etc) we have learned to build and identify the best models for word and sentence prediction.

## Expected results
I expect to be able to predict word completions with decent accuracy (>70%). I still find autocomplete a complete nightmare on iOS, but i'm hoping I can build something better.

## Why is this important
Autocomplete is very useful for consumers on any typing surface. These models not only are valuable to be sold as products/apps, but also contain information on how language is used in communication. The models need to change over time and analyzing the changes in the models tells us how languages are evolving.

## Data Source
[Direct link](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip)